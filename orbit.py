import os
import json
import random
import asyncio
import google.generativeai as genai
from telegram import Bot

# --- ‚ö†Ô∏è HARDCODED SECRETS (PRIVATE REPO ONLY) ‚ö†Ô∏è ---
TELEGRAM_TOKEN = "8512814291:AAEgtDBZDzB4MKz2BdsAjXYk0YLpKzGGO20"
GEMINI_API_KEY = "AIzaSyDRthGk2azAa8EcJYfzWfHmpuz8Z_Z5fGU"
CHAT_ID = "6882899041"

# --- CONFIGURATION ---
genai.configure(api_key=GEMINI_API_KEY)

# üõ†Ô∏è AUTO-SELECTOR: Finds a model that actually exists so we stop guessing
def get_working_model():
    try:
        print("üîç Scanning available AI models...")
        # Get all models that support generating text
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # The Wishlist (Best to Worst)
        wishlist = [
            'models/gemini-1.5-flash',
            'models/gemini-1.5-flash-001',
            'models/gemini-1.5-flash-latest',
            'models/gemini-1.5-pro',
            'models/gemini-pro'
        ]
        
        for wish in wishlist:
            if wish in models:
                print(f"‚úÖ Locked on target: {wish}")
                # We strip 'models/' prefix because GenerativeModel() sometimes prefers just the name
                return genai.GenerativeModel(wish.replace("models/", ""))
        
        # If all else fails, pick the first valid Gemini model
        first_option = next((m for m in models if 'gemini' in m), None)
        if first_option:
            print(f"‚ö†Ô∏è Fallback to: {first_option}")
            return genai.GenerativeModel(first_option.replace("models/", ""))
            
    except Exception as e:
        print(f"‚ö†Ô∏è Scan failed: {e}")
    
    # Absolute Hail Mary
    print("ü§û Forcing 'gemini-1.5-flash' and praying...")
    return genai.GenerativeModel('gemini-1.5-flash')

model = get_working_model()

def load_config():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(script_dir, 'config.json')
    try:
        with open(config_path, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"‚ùå CRITICAL ERROR: Could not find config.json at: {config_path}")
        return None

async def send_chaos():
    bot = Bot(token=TELEGRAM_TOKEN)
    config = load_config()
    
    if not config:
        return 

    # üé≤ THE ROLL OF DESTINY (1-100)
    roll = random.randint(1, 100)
    print(f"üé≤ Rolled a {roll}")

    # 1-50: Silence
    if roll <= 50:
        print("Silence is golden. Exiting.")
        return

    # 51-85: Random Fact
    elif 51 <= roll <= 85:
        topic = random.choice(config['interests'])
        prompt = f"Tell me a mind-blowing, short random fact about {topic}. Keep it under 2 sentences."
        try:
            response = model.generate_content(prompt)
            # We use HTML parsing for bold text
            msg = f"üé± <b>Magic-‚àû Fact:</b>\n\n{response.text}"
            await bot.send_message(chat_id=CHAT_ID, text=msg, parse_mode='HTML')
        except Exception as e:
            print(f"Gemini Error: {e}")

    # 86-98: The Grind (NOW WITH ACTUAL QUIZZES)
    elif 86 <= roll <= 98:
        quotes = [
            "Sleep is for the weak. Grind is for the eternal.",
            "You didn't come this far to only come this far.",
            "Surprise! Your brain looks bored.",
            "Error 404: Motivation not found? Too bad.",
            "Lock in. The patient isn't gonna save themselves. ü©∫",
            "Academic Weapon status: Loading... üî´",
            "Imagine failing. Now get back to work.",
            "Your competition is studying right now. Are you?",
            "Pain is temporary. The 'Dr.' title is forever. ü•º",
            "Stop scrolling. Start solving.",
            "This unit won't learn itself, chief.",
            "Be the main character in your own success story.",
            "Coffee in. Knowledge out. ‚òï",
            "Diamonds are made under pressure. So are you.",
            "The charts are moving. Why aren't you? üìâ",
            "Houston, we have a problem: You aren't studying. üöÄ",
            "Coding is just wizardry. Go cast a spell. üßô‚Äç‚ôÇÔ∏è",
            "If it was easy, everyone would do it.",
            "Don't practice until you get it right. Practice until you can't get it wrong.",
            "Future you is begging you to lock in right now."
        ]
        unit = random.choice(config['current_units'])
        quote = random.choice(quotes)
        
        # 1. Hype Message
        await bot.send_message(chat_id=CHAT_ID, text=f"üö® <b>{quote}</b>\n\nIncoming Pop Quiz: <b>{unit}</b>", parse_mode='HTML')
        
        # 2. Generate Quiz
        prompt = f"""
        Generate a multiple-choice quiz question about {unit} for a 4th Year University Student.
        Respond ONLY with valid JSON in this format:
        {{
            "question": "The question text?",
            "options": ["A", "B", "C", "D"],
            "correct_id": 0,
            "explanation": "Brief explanation."
        }}
        """
        try:
            response = model.generate_content(prompt)
            # Clean JSON (Gemini loves adding ```json backticks)
            text = response.text.replace('```json', '').replace('```', '').strip()
            quiz_data = json.loads(text)
            
            # 3. Send Poll
            await bot.send_poll(
                chat_id=CHAT_ID,
                question=quiz_data['question'],
                options=quiz_data['options'],
                type="quiz",
                correct_option_id=quiz_data['correct_id'],
                explanation=quiz_data['explanation']
            )
        except Exception as e:
            print(f"Quiz Generation Failed: {e}")
            await bot.send_message(chat_id=CHAT_ID, text="‚ö†Ô∏è AI Brain Freeze. Just go read a book.")

    # 99-100: GOD MODE
    else:
        await bot.send_message(chat_id=CHAT_ID, text="üëë <b>GOD MODE ACTIVATED</b>\n\nPrepare yourself...", parse_mode='HTML')

if __name__ == "__main__":
    asyncio.run(send_chaos())
